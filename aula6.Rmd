---
title: "Tutorial Biologia Evolutiva 2017"
author: "Diogo Melo"
date: "October 23, 2017"
output:
  html_document:
    highlight: tango
    number_sections: yes
    theme: flatly
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: no
  pdf_document:
    toc: yes
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Leitura da Aula 6

- [SIZE AS A LINE OF LEAST EVOLUTIONARY RESISTANCE: DIET AND ADAPTIVE MORPHOLOGICAL RADIATION IN NEW WORLD MONKEYS](http://onlinelibrary.wiley.com/doi/10.1111/j.0014-3820.2005.tb01049.x/abstract) ([pdf](https://github.com/lem-usp/site-bio208/raw/master/static/pdfs/artigos/Marroig%2C%20Cheverud%20-%202005%20-%20Size%20as%20a%20line%20of%20least%20evolutionary%20resistance%20diet%20and%20adaptive%20morphological%20radiation%20in%20New%20World%20monkey.pdf))

    __Abstract:__
    New World monkeys (NWM) display substantial variation (two orders of magnitude) in body size. Despite this, variation in skull size and associated shape show a conserved allometric relationship, both within and between genera. Maximum likelihood estimates of quantitative ancestral states were used to compare the direction of morphological differentiation with the phenotypic (pmax) and genetic (gmax) lines of least evolutionary resistance (LLER). Diversification in NWM skulls occurred principally along the LLER defined by size variation. We also obtained measures of morphological amount and pace of change using our skull data together with published genetic distances to test whether the LLER influenced the amount and pace of diversification. Moreover, data on an ecological factor (diet) was obtained from the literature and used to test the association of this niche-related measure with the morphological diversification. Two strategies were used to test the association of LLER with the morphological and dietary amount and pace of change, one focusing on both contemporary genera and maximum likelihood reconstructed ancestors and the other using only the 16 contemporary genera in a phylogenetic comparative analysis. Our results suggest that the LLER influenced the path, amount, and pace of morphological change. Evolution also occurred away from the LLER in some taxa but this occurred at a slower pace and resulted in a relatively low amount of morphological change. We found that longer branch lengths (time) are associated with larger differences in pmax orientation. However, on a macroevolutionary scale there is no such trend. Diet is consistently associated with both absolute size differences and morphological integration patterns, and we suggest that this ecological factor might be driving adaptive radiation in NWM. Invasion of diet-based adaptive zones involves changes in absolute size, due to metabolic and foraging constraints, resulting in simple allometric skull diversification along the LLER. While it is clear that evolutionary change occurred along the LLER, it is not clear whether this macroevolutionary pattern results from a conservation of within-population genetic covariance patterns or long-term adaptation along a size dimension or whether both constraints and selection were inextricably involved.

## Leitura complementar para ter os $\beta$ corretos:

- [MODULARITY, NOISE, AND NATURAL SELECTION](http://onlinelibrary.wiley.com/doi/10.1111/j.1558-5646.2011.01555.x/full) ([pdf](https://github.com/lem-usp/site-bio208/raw/master/static/pdfs/artigos/Marroig%2C%20Melo%2C%20Garcia%20-%202012%20-%20Modularity%2C%20noise%2C%20and%20natural%20selection.pdf))

    __Abstract:__
    Most biological systems are formed by component parts that are to some degree interrelated. Groups of parts that are more associated among themselves and are relatively autonomous from others are called modules. One of the consequences of modularity is that biological systems usually present an unequal distribution of the genetic variation among traits. Estimating the covariance matrix that describes these systems is a difficult problem due to a number of factors such as poor sample sizes and measurement errors. We show that this problem will be exacerbated whenever matrix inversion is required, as in directional selection reconstruction analysis. We explore the consequences of varying degrees of modularity and signal-to-noise ratio on selection reconstruction. We then present and test the efficiency of available methods for controlling noise in matrix estimates. In our simulations, controlling matrices for noise vastly improves the reconstruction of selection gradients. We also perform an analysis of selection gradients reconstruction over a New World Monkeys skull database to illustrate the impact of noise on such analyses. Noise-controlled estimates render far more plausible interpretations that are in full agreement with previous results.

# Objetivos da aula 6

- Calcular os gradientes de seleção ($\beta$) ao longo da filogenia
- Calcular a correlação entre gradientes de seleção resposta à seleção ($\Delta z$)

## Equação do criador

Para entender a equação de resposta à seleção, vamos lembrar da herdabilidade (relacionada com a covariância entre pais e filhos). Pense que temos uma população expressando um caráter quantitativo qualquer com herdabilidade ($h^2$) de 0.6. Isso significa que nessa população, se fizermos uma gráfico com a média do valor do caráter nos pais no eixo $x$ e o valor do caráter dos filhos no eixo $y$, centralizando o grafico na média dos pais, teriamos alguma coisa assim:

```{r, echo = FALSE}
library(mvtnorm)
library(ggplot2)
set.seed(42)
x = rnorm(100, 0, 1)
y = 0.6 * x + rnorm(100, 0, 0.3)
data = as.data.frame(scale(data.frame(x, y), scale = FALSE))
model = lm(data$y ~ data$x)
c = coef(model)
ggplot(data, aes(x, y)) + geom_point() + theme_bw() + coord_fixed() + labs(x = "Fenótipo dos pais", y = "Fenótipo dos filhos") + geom_hline(yintercept = 0) + geom_vline(xintercept = 0)
```

Nesta população, vamos aplicar um regime de seleção direcional no fenótipo dos pais. Apenas pais com fenótipo uma unidade maior que á média irão deixar descendentes. Vamos usar o gráfico para descobrir a nova média dos filhos:

```{r, echo = FALSE}
x_mean = mean(data[data$x > 1, "x"])
y_mean = mean(data[data$x > 1, "y"])
shade <- data.frame(x = c(1, 1, 2.5, 2.5, 1), y = c(-2, 2, 2, -2, -2))
ggplot(data, aes(x, y)) + geom_polygon(data = shade, aes(x, y), fill = "lightblue", alpha = 0.5) + geom_point() + theme_bw() + coord_fixed() + labs(x = "Fenótipo dos pais", y = "Fenótipo dos filhos") + geom_hline(yintercept = 0) + geom_vline(xintercept = 0) + geom_smooth(method = "lm", color = "blue", se = FALSE) + geom_segment(x = x_mean, xend=x_mean, y = 0, yend = c[2] * x_mean, linetype = "dashed", size = 2)  + geom_segment(x = 0, xend=x_mean, y = c[2] * x_mean, yend = c[2] * x_mean, linetype = "dashed", size = 2)
```

A região em azul representa o limiar de seleção (apenas pais maiores que 1 deixam descententes). A média dos pais depois da seleção está marcada pela linha tracejada vertical. Usando uma regressão linear, podemos descobrir a média dos filhos dos pais que sobrevivem à seleção. A linha tracejada horizontal marca a média dos filhos após a seleção. O coeficiente de inclinação da regressão entre pais e filhos é a herdabilidade do caráter na população. Como nós centralizamos os pais e a reta de regressão passa pelo zero, sabemos que a média dos pais e filhos antes da seleção eram iguais.

A diferença entre a média dos pais antes e depois da seleção é chamada de diferencial de seleção ($S$), enquanto a diferença na média dos filhos é chamada de resposta à seleção ($R$). A razão entre ela, ou o coeficiente da inclinação da reta de regressão entre pais e filhos, ou a tangente do ângulo da reta, é a herdabilidade ($h^2$). Graficamente:

```{r, echo = FALSE}
S = data.frame(x = c(0, 0, x_mean, x_mean),
               y = c(0, - 0.1, - 0.1, 0))

R = data.frame(x = c(-0.1, -0.1, 0),
               y = c(0, c[2] * x_mean, c[2] * x_mean))

ggplot(data, aes(x, y)) + geom_polygon(data = shade, aes(x, y), fill = "lightblue", alpha = 0.5) + geom_point(alpha = 0.3) + theme_bw() + coord_fixed() + labs(x = "Fenótipo dos pais", y = "Fenótipo dos filhos") + geom_hline(yintercept = 0) + geom_vline(xintercept = 0) + geom_smooth(method = "lm", color = "blue", se = FALSE) + geom_segment(x = x_mean, xend=x_mean, y = 0, yend = c[2] * x_mean, linetype = "dashed", size = 2)  + geom_segment(x = 0, xend=x_mean, y = c[2] * x_mean, yend = c[2] * x_mean, linetype = "dashed", size = 2) + geom_line(data = S, color = "red") + annotate("text", x = 0.7, y = -0.2, label = "S", size = 5) + geom_line(data = R, color = "red") + annotate("text", x = -0.2, y = 0.45, label = "R", size = 5) + geom_segment(x = -0.1, xend = 0, y = 0, yend = 0, color = "red")
```

Juntando tudo isso, podemos escrever a equação do criador:

$$
R = h^2S
$$

Ou seja, a resposta à seleção direcional é uma combinação entre a intensidade de seleção (quanto maior o $S$ maior a intensidade de seleção) e a variação disponível que é herdável (a herdabilidade, a regressão entre pais e filhos). Nesse caso, temos $S = 1.44$, $h^2 = 0.6$ e, portanto, $R = 0.87$.

Em condições razoáveis, o coeficiente da regressão entre pais e filhos vai ser igual à razão entre a variância nos valores de acasalamento dos pais (variancia aditiva, $V_a$) e a variância fenotípica total ($V_p$). Por isso, é comum encontrarmos a equação do criador escrita como $R = \frac{V_a}{V_p}S$ nos livros texto. A formulação como a regressão entre pais e filhos é mais geral, e a versão usando a partição de variâncias é mais fácil de ser mensurada.

## Equação de Lande

O que acontece quando temos mais de um caráter no sistema? Para entender o problema, pense que estamos olhando para dois caracteres nos pais, e aplicando seleção em apenas um deles. Imagine que esses dois caracteres tenham uma correlação fenotípica de 0.8 entre eles:

```{r, echo = FALSE}
set.seed(42)
xy = data.frame(rmvnorm(100, sigma = matrix(c(1, 0.8, 0.8, 1), 2, 2)))
names(xy) = c("x","y")
shade <- data.frame(x = c(1, 1, 2.5, 2.5, 1), y = c(-2, 2.8, 2.8, -2.5, -2.5))
ggplot(xy, aes(x, y)) + geom_polygon(data = shade, aes(x, y), fill = "lightblue", alpha = 0.5) + geom_point() + theme_bw() + coord_fixed() + labs(x = "Caráter x nos pais", y = "Caráter y nos pais") + geom_hline(yintercept = 0) + geom_vline(xintercept = 0)
```

Da mesma forma que a correlação entre pais e filhos impõem uma resposta, a correlação entre caracteres impõem um diferencial de seleção correlacionado. Então, se existe um $S_x$, a correlação entre $x$ e $y$ leva a um $S_y$:

```{r, echo = FALSE}
x_mean = mean(xy[xy$x > 1, "x"])
y_mean = mean(xy[xy$x > 1, "y"])
S_x = data.frame(x = c(0, 0, x_mean, x_mean),
               y = c(0, - 0.1, - 0.1, 0))

S_y = data.frame(x = c(-0.1, -0.1, 0),
               y = c(0, y_mean, y_mean))

ggplot(xy, aes(x, y)) + geom_polygon(data = shade, aes(x, y), fill = "lightblue", alpha = 0.5) +
  geom_point(alpha = 0.3) + theme_bw() + coord_fixed() +
  labs(x = "Caráter x nos pais", y = "Caráter y nos pais") +
  geom_hline(yintercept = 0) + geom_vline(xintercept = 0) +
  geom_line(data = S_x, color = "red") + annotate("text", x = x_mean/2, y = -0.3, label = "S[x]", size = 5, parse = TRUE) +
  geom_line(data = S_y, color = "red") + annotate("text", x = -0.3, y = y_mean/2, label = "S[y]", size = 5, parse = TRUE) +
  geom_segment(x = -0.1, xend = 0, y = 0, yend = 0, color = "red")
```

Esse fenômeno do diferencial de seleção correlacionado complica nossa vida, afinal, como saber qual caráter está sofrendo seleção? Nesse caso, $S = [S_x, S_y] = [1.43, 1.15]$, ambos os caracteres tem médias diferentes depois da seleção. A solução é transformar os dados, colocando eles na escala da matriz de covariação fenotípica. Fazemos isso multiplicando os dados pelo inverso da matriz fenotípica, e o resultado é o seguinte:

```{r, echo = FALSE}
P = cov(xy)
xy_p = data.frame(as.matrix(xy) %*% solve(P))
xy_p = data.frame(t(apply(as.matrix(xy), 1, function(x) solve(P, x))))
names(xy_p) = c("x", "y")
xy_p$Selection = ifelse(xy$x > 1, "Survives", "Dies")
shade <- data.frame(x = c(1, 1, 2.5, 2, 1), y = c(0, 2, 3, 0, 0))
shade_p = data.frame(t(apply(as.matrix(shade), 1, function(x) solve(P, x))))
x_mean = mean(xy_p[xy$x > 1, "x"])
y_mean = mean(xy_p[xy$x > 1, "y"])
shade_p$Selection = "Survives"

ggplot(xy_p, aes(x, y)) + geom_polygon(data = shade_p, aes(x, y), fill = "lightblue", alpha = 0.5) +
  geom_point(alpha = 0.3) + theme_bw() + coord_fixed() +
  labs(x = "Caráter x nos pais (Escala de P)", y = "Caráter y nos pais (Escala de P)") +
  geom_hline(yintercept = 0) + geom_vline(xintercept = 0) +
  geom_line(data = S_x, color = "red") + annotate("text", x = x_mean/3, y = -0.35, label = "beta[x]", size = 5, parse = T)
```

A região azul continua representando os indivíduos que sobrevivem à seleção. Mas agora a diferença nas médias antes e depois da seleção só é diferente de zero no caráter $x$ (só $x$ está sobre seleção). Essas diferenças nas médias antes e depois da seleção, medidas na escala da variância fenotípica, são chamadas de gradientes de seleção ($\beta$), e já descontam o efeito das correlações fenotípicas. Olhando para o $\beta$, que nesse caso é o vetor $\beta = [\beta_x, \beta_y] = [1.5, 0]$, sabemos que só o caráter $x$ está sofrendo seleção direcional.

Se vai haver resposta correlacionada do caráter $y$ na próxima geração depende de se os dois caracteres são correlacionados genéticamente. Um jeito de entender isso é pensar que para que haja resposta em $y$, os filhos dos pais selecionados (com $x$ acima de 1) tem que ser diferentes da média no cárater $y$. Então, a resposta depende de haver covariância entre pais e filhos para caracteres diferentes. Em condições razoáveis, a matriz de covariância genética é uma boa aproximação da covariância entre pais e filhos, e podemos prever a resposta no caráter $y$ ($\Delta z_y$) usando a matriz $G$:

$$
\Delta z_y = G_{y} \times \beta_y + G_{xy} \times \beta_{x}
$$

Ou seja, a seleção diretamente em $y$ (dada por $\beta_y$) multiplicado pela variância genética de $y$ ($G_{y}$), mais a seleção em $x$ ($\beta_x$) multiplicado pela covariância genética entre $x$ e $y$ ($G_{xy}$). No nosso exemplo, $\beta_y = 0$ e só haverá resposta evolutiva em $y$ se $G_{xy}$ for diferente de zero.

Da mesma forma, podemos escrever a resposta no caráter $x$:

$$
\Delta z_x = G_{x} \times \beta_x + G_{xy} \times \beta_{y}
$$

Podemos juntar essas duas equação numa só usando uma notação vetorial:

$$
\Delta z =
\left[
\begin{matrix}
\Delta z_x \\
\Delta z_y
\end{matrix} \right]
=
\left[
\begin{matrix}
G_x & G_{xy} \\
G_{xy} & G_y \\
\end{matrix} \right]
\left[
\begin{matrix}
\beta_x \\
\beta_y
\end{matrix} \right]
=
G\beta
$$

Essa é a equação multivariada de resposta à seleção, ou a Equação de Lande. É a equação mais cool, como podemos ver nessa foto:

```{r, out.width = "400px", echo = FALSE}
knitr::include_graphics("lande.jpg")
```

Podemos escrever a resposta à seleção em função dos diferenciais de seleção, lembrando que o gradiente de seleção é o diferencial escrito na escala da P. Nesse caso, a equação fica:

$$
\Delta z = G\beta = GP^{-1}S
$$

Comparando essa equação com a equação do criador, vemos que $GP^{-1}$ é a quantidade análoga à herdabilidade para vários caracteres.

## Estimando $\beta$

Agora que sabemos o que o $\beta$ representa e como interpretar seus valores, vamos pensar na informação que normalmente temos na natureza. Nós já estimamos as matrizes de covariância e os vetores de mudança fenotípica ($\Delta z$), como podemos usar essa informação para entender o padrão de seleção natural? Como podemos estimar o $\beta$ que teria sido responsável pela mudança fenotípica observada?

Vamos pensar no sistema de equações que escrevemos ali em cima:

$$
\begin{align}
\Delta z_x &= G_{x} \times \beta_x + G_{xy} \times \beta_{y} \\
\Delta z_y &= G_{y} \times \beta_y + G_{xy} \times \beta_{x}
\end{align}
$$

Parece bom, se sabemos a matriz G (no nosso caso usamos a P como aproximação da G), sabemos o $\Delta z$, temos duas equações e duas incognitas, podemos achar o $\beta$. No R, um sistema de equações desse tipo pode ser resolvido usando a forma matricial

$$
\Delta z = G\beta
$$

A função solve() recebe a matriz de coeficientes G e o vetor de soluções $\Delta z$, e devolve o vetor de solução $\beta$.
Por exemplo, se $\beta = [1, 2]$  e G tem variâncias iguais a 2 e covariância 1.2, o $\Delta z$ esperado é:

```{r}
beta = c(1, 2)
G = matrix(c(2, 1.2,
             1.2, 2), 2, 2)
G %*% beta
```

Então, se estamos medindo uma população, e observamos um $\Delta z = [4.4, 5.2]$ e uma matriz G com variâncias 2 e covariância 1.2, podemos calcular beta usando a equação:

$$
\begin{align}
2 \times \beta_x + 1.2 \times \beta_{y} &= 4.4\\
2 \times \beta_y + 1.2 \times \beta_{x} &= 5.2
\end{align}
$$

No R, isso seria:

```{r}
deltaZ = c(4.4, 5.2)
G = matrix(c(2, 1.2,
             1.2, 2), 2, 2)
solve(G, deltaZ)
```

Que é exatamente o $\beta$ que nós usamos no começo.

## Estimando $\beta$ nos dados

Agora vamos tentar o mesmo com algum ramo da nossa filogenia. Primeiro vamos rapidamente recalcular as médias e matrizes ancestrais:

```{r, message=FALSE, warning=FALSE}
if(!require(evolqg)){install.packages("evolqg"); library(evolqg)}
data(dentus)

# Matrizes atuais
cov_matrices = dlply(dentus, .(species), function(x) cov(x[,1:4]))

# Filogenia
if(!require(ape)){install.packages("ape"); library(ape)}
TREE <- "(E:3,((C:1,B:1):1,(D:1, A:1):1):1):1;"
tree <- read.tree(text = TREE)
tree$tip.label = c("E", "C", "B", "D", "A")
tree$node.label = c("root", "ABCD", "CB", "AD")

# Matrizes ancestrais
all_cov_matrices = PhyloW(tree, cov_matrices)
attributes(all_cov_matrices)$split_labels = attributes(all_cov_matrices)$names

# Medias atuais
dentus_means = ddply(dentus, "species", numcolwise(mean))

# Medias ancestrais
if(!require(ape)){install.packages("ape"); library(ape)}
dentus_ancestral = sapply(dentus_means[2:5], function(x) {
  names(x) = as.character(dentus_means[,1])
  ace(x, tree)$ace
})

dentus_ancestral = data.frame(species = c("root", "ABCD", "CB", "AD"), dentus_ancestral)
dentus_means_ace = rbind(dentus_means, dentus_ancestral)
all_means = dlply(dentus_means_ace, .(species), numcolwise(identity))
```

Agora vamos fazer os $\Delta z$ de uma vez só, segurem seus chapéus.

```{r}
node_names = c(tree$tip.label, tree$node.label)
node_numbers = c(1:5, 7:9)
delta_Zs = vector("list", 8)
for(i in seq(8)){
  node = node_numbers[i]
  current_node = node_names[node]
  node_mean = all_means[[current_node]]
  ancestral_node = node_names[tree$edge[tree$edge[,2] == node, 1]]
  ancestral_mean = all_means[[ancestral_node]]
  delta_Zs[[i]] = node_mean - ancestral_mean
}
names(delta_Zs) = node_names[-6]
```

Um pouco elaborado, mas bem mais fácil que fazer na mão. Agora podemos acessar o $\Delta z$ pelo nome do nó derivado. O $\Delta z$ no ramo E-root então é:

```{r}
delta_Zs$E
```

Podemos também colocar isso em forma de tabela:

```{r}
deltaZ_table = ldply(delta_Zs)
deltaZ_table
```

Ou salvar em um arquivo:

```{r}
write.csv(deltaZ_table, "meu_arquivo_de_deltaZs.csv")
```

Agora temos os $\Delta z$ e as matrizes, podemos estimar os $\beta$ ao longo da filogenia. Por exemplo, o $\beta$ no ramo C-CB:

```{r}
beta_C_CB = solve(all_cov_matrices$CB, delta_Zs$C)
beta_C_CB
```

Ou seja, aumento dos membros anteriores e diminuição dos posteriores. Vamos agora tentar entender o que esse $\beta$ significa.

## Comparação de $\Delta z$ e $\beta$

Usando a espécie C como exemplo, vamos usar a correlação de vetores para interpretar a história evolutiva dessa espécie. Primeiro vamos definir a função de correlação de vetores:

```{r}
# Vamos usar funçòes do R e do evolqg para fazer isso em uma linha
corVector = function(x, y) sum(x * y)/(Norm(x) * Norm(y))
```

Temos duas comparações importantes a serem feitas: (1) entre a mudança evolutiva e o padrão de covariação, (2) e entre a mudança evolutiva e a seleção natural. Vamos lá:

```{r}
# Auto decomposição da matriz
eigCB = eigen(all_cov_matrices$CB)

# Variancia explicada por cada PC:
eigCB$values / sum(eigCB$values) * 100

# Primeiro e segundo PCs
PC1_CB = eigCB$vectors[,1]
PC2_CB = eigCB$vectors[,2]

# Correlação entre PCs e deltaZ
# Nos usamos a funçao abs (valor absoluto) aqui pq o sinal de uma correlação com um PC não interessa.
# Isso pq PCs são direções e não sentidos.
abs(corVector(delta_Zs$C, PC1_CB))
abs(corVector(delta_Zs$C, PC2_CB))

# Correlação entre beta e delta Z.
# Aqui o sinal da correlação interessa
# correlações negativas indicam seleção pra um lado e resposta pro outro.
corVector(delta_Zs$C, beta_C_CB)
```

Então, ficamos assim: correlações baixas entre $\Delta z$ e os primeiros componentes (0.07 e 0.58), mesmo eles explicando conjuntamente 75\% (52 + 23) da variação total. Isso exclui a hipótese de restrição evolutiva. Mas, quando olhamos a correlação entre seleção e resposta, temos uma correlação de 0.97, indicando que a diversificação da espécie C se deu de forma alinhada com a seleção (e não seguindo a linha de menor resistência, como vimos com a correlação de 0.07 com o PC1). Sabemos também que a seleção foi para aumentar os membros anteriores e diminuir os posteriores. Será que o habito de vida dessa espécie pode trazer alguma pista?

Agora, faça essa análise para todas as espécies e nós internos.